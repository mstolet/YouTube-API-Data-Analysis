{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a744d8d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>title</th>\n",
       "      <th>view_count</th>\n",
       "      <th>like_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5iz1nncUPLc</td>\n",
       "      <td>GANHADORES DO BBB QUE PERDERAM TUDO! | Virou F...</td>\n",
       "      <td>34863</td>\n",
       "      <td>5716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KhE2BQ0ce7U</td>\n",
       "      <td>ELIEZER É CANCELADO POR RECLAMAR DE CHEIRO DE ...</td>\n",
       "      <td>122610</td>\n",
       "      <td>10133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-HyIwsKMRF0</td>\n",
       "      <td>BBB 23: DOMITILA DIZ QUE ALINE JÁ DEVERIA TER ...</td>\n",
       "      <td>6585</td>\n",
       "      <td>718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POxBUpCk9s8</td>\n",
       "      <td>BBB 23: ANA MARIA CHOCA DOMITILA COM VERDADES ...</td>\n",
       "      <td>89238</td>\n",
       "      <td>10810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SRCE9H1tFMQ</td>\n",
       "      <td>GLOBO CORTA CUSTOS E TREINA REPÓRTERES PARA SE...</td>\n",
       "      <td>5137</td>\n",
       "      <td>708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>L3-gwB5slxE</td>\n",
       "      <td>SILVIO SANTOS VENDE SBT! | Virou Festa</td>\n",
       "      <td>194458</td>\n",
       "      <td>21210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>nPByZ9jQWq8</td>\n",
       "      <td>BBB 22: JADE PICON REVELA SEM QUERER QUE ESTÁ ...</td>\n",
       "      <td>108575</td>\n",
       "      <td>11373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>hBj1BC7m1NQ</td>\n",
       "      <td>BBB 22: GLOBO TEME FRACASSO, FAZ MUDANÇAS DRÁS...</td>\n",
       "      <td>267583</td>\n",
       "      <td>24566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>8bS-g5rcaDI</td>\n",
       "      <td>GLOBO PERDE MAIS PUBLICO, FECHA 2021 COM A PIO...</td>\n",
       "      <td>149480</td>\n",
       "      <td>19563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>AyQ6qjv8s-E</td>\n",
       "      <td>A FAZENDA: ALINE E MC GUI DÃO O QUE FALAR COM ...</td>\n",
       "      <td>113141</td>\n",
       "      <td>2105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>501 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        video_id                                              title  \\\n",
       "0    5iz1nncUPLc  GANHADORES DO BBB QUE PERDERAM TUDO! | Virou F...   \n",
       "1    KhE2BQ0ce7U  ELIEZER É CANCELADO POR RECLAMAR DE CHEIRO DE ...   \n",
       "2    -HyIwsKMRF0  BBB 23: DOMITILA DIZ QUE ALINE JÁ DEVERIA TER ...   \n",
       "3    POxBUpCk9s8  BBB 23: ANA MARIA CHOCA DOMITILA COM VERDADES ...   \n",
       "4    SRCE9H1tFMQ  GLOBO CORTA CUSTOS E TREINA REPÓRTERES PARA SE...   \n",
       "..           ...                                                ...   \n",
       "496  L3-gwB5slxE             SILVIO SANTOS VENDE SBT! | Virou Festa   \n",
       "497  nPByZ9jQWq8  BBB 22: JADE PICON REVELA SEM QUERER QUE ESTÁ ...   \n",
       "498  hBj1BC7m1NQ  BBB 22: GLOBO TEME FRACASSO, FAZ MUDANÇAS DRÁS...   \n",
       "499  8bS-g5rcaDI  GLOBO PERDE MAIS PUBLICO, FECHA 2021 COM A PIO...   \n",
       "500  AyQ6qjv8s-E  A FAZENDA: ALINE E MC GUI DÃO O QUE FALAR COM ...   \n",
       "\n",
       "     view_count  like_count  \n",
       "0         34863        5716  \n",
       "1        122610       10133  \n",
       "2          6585         718  \n",
       "3         89238       10810  \n",
       "4          5137         708  \n",
       "..          ...         ...  \n",
       "496      194458       21210  \n",
       "497      108575       11373  \n",
       "498      267583       24566  \n",
       "499      149480       19563  \n",
       "500      113141        2105  \n",
       "\n",
       "[501 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "\n",
    "# Set the API key and YouTube API parameters\n",
    "DEVELOPER_KEY = \"AIzaSyCJIPXQboD4ExbjP8SlXi6mlbvjPCslqMQ\"\n",
    "YOUTUBE_API_SERVICE_NAME = \"youtube\"\n",
    "YOUTUBE_API_VERSION = \"v3\"\n",
    "\n",
    "# Create the API client\n",
    "youtube = build(YOUTUBE_API_SERVICE_NAME, YOUTUBE_API_VERSION, developerKey=DEVELOPER_KEY)\n",
    "\n",
    "# Replace CHANNEL_URL with your desired channel URL\n",
    "CHANNEL_URL = 'https://www.youtube.com/@VirouFestaTV'\n",
    "\n",
    "# Send a GET request to the channel URL\n",
    "response = requests.get(CHANNEL_URL)\n",
    "\n",
    "# Extract the channel name from the response HTML\n",
    "match = re.search(r'\"channelId\":\"(.*?)\"', response.text)\n",
    "channel_id = match.group(1)\n",
    "\n",
    "# Set the maximum number of videos to retrieve. You can adjust this as needed.\n",
    "MAX_RESULTS = 50\n",
    "\n",
    "# Retrieve the video data from the API\n",
    "videos = []\n",
    "next_page_token = None\n",
    "\n",
    "while True:\n",
    "    # Use the search endpoint to retrieve videos from the channel\n",
    "    search_response = youtube.search().list(\n",
    "        q=\"\",\n",
    "        type=\"video\",\n",
    "        channelId=channel_id,\n",
    "        part=\"id\",\n",
    "        order=\"date\",\n",
    "        maxResults=MAX_RESULTS,\n",
    "        pageToken=next_page_token\n",
    "    ).execute()\n",
    "    \n",
    "    # Use the videos endpoint to retrieve details about each video\n",
    "    video_ids = [search_result[\"id\"][\"videoId\"] for search_result in search_response.get(\"items\", [])]\n",
    "    video_response = youtube.videos().list(\n",
    "        id=\",\".join(video_ids),\n",
    "        part=\"snippet,statistics\"\n",
    "    ).execute()\n",
    "    \n",
    "    # Append the video data to the list of videos\n",
    "    videos += video_response.get(\"items\", [])\n",
    "    \n",
    "    # Check for additional pages of results\n",
    "    next_page_token = search_response.get(\"nextPageToken\")\n",
    "    if next_page_token is None:\n",
    "        break\n",
    "        \n",
    "# Create a dataframe to store the video data\n",
    "video_data = []\n",
    "for video in videos:\n",
    "    # Basic information\n",
    "    video_id = video[\"id\"]\n",
    "    title = video[\"snippet\"][\"title\"]\n",
    "    \n",
    "    # Statistics\n",
    "    statistics = video.get(\"statistics\", {})\n",
    "    view_count = int(statistics.get(\"viewCount\", 0))\n",
    "    like_count = int(statistics.get(\"likeCount\", 0))\n",
    "    \n",
    "    # Append the video data to the list of videos\n",
    "    video_data.append({\"video_id\": video_id, \"title\": title, \"view_count\": view_count, \"like_count\": like_count})\n",
    "\n",
    "# Create a dataframe from the video data\n",
    "df = pd.DataFrame(video_data, columns=[\"video_id\", \"title\", \"view_count\", \"like_count\"])\n",
    "\n",
    "# Print the dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39f6c895",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-11-b923787472fc>, line 60)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-11-b923787472fc>\"\u001b[1;36m, line \u001b[1;32m60\u001b[0m\n\u001b[1;33m    fields=\"items/snippet/publishedAt,items/snippet/title,\u001b[0m\n\u001b[1;37m                                                          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "\n",
    "# Set up the YouTube API client\n",
    "DEVELOPER_KEY = \"AIzaSyCJIPXQboD4ExbjP8SlXi6mlbvjPCslqMQ\"\n",
    "YOUTUBE_API_SERVICE_NAME = \"youtube\"\n",
    "YOUTUBE_API_VERSION = \"v3\"\n",
    "youtube = build(YOUTUBE_API_SERVICE_NAME, YOUTUBE_API_VERSION, developerKey=DEVELOPER_KEY)\n",
    "\n",
    "# Replace CHANNEL_URL with your desired channel URL\n",
    "CHANNEL_URL = 'https://www.youtube.com/user/PewDiePie'\n",
    "\n",
    "# Send a GET request to the channel URL\n",
    "response = requests.get(CHANNEL_URL)\n",
    "\n",
    "# Extract the channel name from the response HTML\n",
    "match = re.search(r'\"channelId\":\"(.*?)\"', response.text)\n",
    "channel_id = match.group(1)\n",
    "\n",
    "# Set the start and end dates\n",
    "end_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "start_date = (datetime.datetime.now() - datetime.timedelta(days=5)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Call the YouTube API to get the channel statistics\n",
    "results = youtube.channels().list(\n",
    "    part=\"statistics\",\n",
    "    id=channel_id,\n",
    "    fields=\"items/statistics\"\n",
    ").execute()\n",
    "\n",
    "# Create a DataFrame with the channel statistics\n",
    "data = [\n",
    "    {\n",
    "        \"date\": end_date,\n",
    "        \"views\": int(results[\"items\"][0][\"statistics\"][\"viewCount\"]),\n",
    "        \"subscribers\": int(results[\"items\"][0][\"statistics\"][\"subscriberCount\"]),\n",
    "        \"videos\": int(results[\"items\"][0][\"statistics\"][\"videoCount\"])\n",
    "    }\n",
    "]\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Call the YouTube API again to get the channel statistics from 5 days ago\n",
    "results = youtube.search().list(\n",
    "    part=\"snippet\",\n",
    "    channelId=channel_id,\n",
    "    type=\"video\",\n",
    "    publishedAfter=start_date + \"T00:00:00Z\",\n",
    "    publishedBefore=end_date + \"T00:00:00Z\",\n",
    "    maxResults=50\n",
    ").execute()\n",
    "\n",
    "# Loop through the search results and add the views, likes, dislikes, comments, and title for each video to the DataFrame\n",
    "for item in results[\"items\"]:\n",
    "    video_id = item[\"id\"][\"videoId\"]\n",
    "    video_results = youtube.videos().list(\n",
    "        part=\"snippet,statistics\",\n",
    "        id=video_id,\n",
    "        fields=\"items/snippet/publishedAt,items/snippet/title,\n",
    "\n",
    "    ).execute()\n",
    "    df.loc[df.shape[0]] = {\n",
    "        \"date\": video_results[\"items\"][0][\"snippet\"][\"publishedAt\"][:10],\n",
    "        \"video_title\": video_results[\"items\"][0][\"snippet\"][\"title\"],\n",
    "        \"video_views\": int(video_results[\"items\"][0][\"statistics\"].get(\"viewCount\", 0)),\n",
    "        \"video_likes\": int(video_results[\"items\"][0][\"statistics\"].get(\"likeCount\", 0)),\n",
    "        \"video_dislikes\": int(video_results[\"items\"][0][\"statistics\"].get(\"dislikeCount\", 0)),\n",
    "        \"video_comments\": int(video_results[\"items\"][0][\"statistics\"].get(\"commentCount\", 0))\n",
    "    }\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48144987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>views</th>\n",
       "      <th>subscribers</th>\n",
       "      <th>videos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-04-22</td>\n",
       "      <td>401606520.0</td>\n",
       "      <td>943000.0</td>\n",
       "      <td>977.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-04-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-04-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-04-17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-04-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-04-20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date        views  subscribers  videos\n",
       "0  2023-04-22  401606520.0     943000.0   977.0\n",
       "1  2023-04-19          NaN          NaN     NaN\n",
       "2  2023-04-18          NaN          NaN     NaN\n",
       "3  2023-04-17          NaN          NaN     NaN\n",
       "4  2023-04-21          NaN          NaN     NaN\n",
       "5  2023-04-20          NaN          NaN     NaN"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "\n",
    "# Set up the YouTube API client\n",
    "DEVELOPER_KEY = \"AIzaSyCJIPXQboD4ExbjP8SlXi6mlbvjPCslqMQ\"\n",
    "YOUTUBE_API_SERVICE_NAME = \"youtube\"\n",
    "YOUTUBE_API_VERSION = \"v3\"\n",
    "youtube = build(YOUTUBE_API_SERVICE_NAME, YOUTUBE_API_VERSION, developerKey=DEVELOPER_KEY)\n",
    "\n",
    "# Replace CHANNEL_URL with your desired channel URL\n",
    "CHANNEL_URL = 'https://www.youtube.com/user/PewDiePie'\n",
    "\n",
    "# Send a GET request to the channel URL\n",
    "response = requests.get(CHANNEL_URL)\n",
    "\n",
    "# Extract the channel name from the response HTML\n",
    "match = re.search(r'\"channelId\":\"(.*?)\"', response.text)\n",
    "channel_id = match.group(1)\n",
    "\n",
    "# Set the start and end dates\n",
    "end_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "start_date = (datetime.datetime.now() - datetime.timedelta(days=5)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Call the YouTube API to get the channel statistics\n",
    "results = youtube.channels().list(\n",
    "    part=\"statistics\",\n",
    "    id=channel_id,\n",
    "    fields=\"items/statistics\"\n",
    ").execute()\n",
    "\n",
    "# Create a DataFrame with the channel statistics\n",
    "data = [\n",
    "    {\n",
    "        \"date\": end_date,\n",
    "        \"views\": int(results[\"items\"][0][\"statistics\"][\"viewCount\"]),\n",
    "        \"subscribers\": int(results[\"items\"][0][\"statistics\"][\"subscriberCount\"]),\n",
    "        \"videos\": int(results[\"items\"][0][\"statistics\"][\"videoCount\"])\n",
    "    }\n",
    "]\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Call the YouTube API again to get the channel statistics from 5 days ago\n",
    "results = youtube.search().list(\n",
    "    part=\"snippet\",\n",
    "    channelId=channel_id,\n",
    "    type=\"video\",\n",
    "    publishedAfter=start_date + \"T00:00:00Z\",\n",
    "    publishedBefore=end_date + \"T00:00:00Z\",\n",
    "    maxResults=50\n",
    ").execute()\n",
    "\n",
    "# Loop through the search results and add the views, likes, dislikes, comments, and title for each video to the DataFrame\n",
    "for item in results[\"items\"]:\n",
    "    video_id = item[\"id\"][\"videoId\"]\n",
    "    video_results = youtube.videos().list(\n",
    "        part=\"snippet,statistics\",\n",
    "        id=video_id,\n",
    "        fields=\"items/snippet/publishedAt,items/snippet/title,items/statistics/viewCount,items/statistics/likeCount,items/statistics/dislikeCount,items/statistics/commentCount\"\n",
    "    ).execute()\n",
    "    df.loc[df.shape[0]] = {\n",
    "        \"date\": video_results[\"items\"][0][\"snippet\"][\"publishedAt\"][:10],\n",
    "        \"video_title\": video_results[\"items\"][0][\"snippet\"][\"title\"],\n",
    "        \"video_views\": int(video_results[\"items\"][0][\"statistics\"].get(\"viewCount\", 0)),\n",
    "        \"video_likes\": int(video_results[\"items\"][0][\"statistics\"].get(\"likeCount\", 0)),\n",
    "        \"video_dislikes\": int(video_results[\"items\"][0][\"statistics\"].get(\"dislikeCount\", 0)),\n",
    "        \"video_comments\": int(video_results[\"items\"][0][\"statistics\"].get(\"commentCount\", 0))\n",
    "    }\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf4cb30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended video: Jung Hae In&#39;s Travel Log : Cooking [Jung Hae In’s Travel Log Ep 6]\n",
      "URL: https://www.youtube.com/watch?v=8XLEfhM1dks\n"
     ]
    }
   ],
   "source": [
    "from googleapiclient.discovery import build\n",
    "\n",
    "# Set the API key\n",
    "api_key = \"AIzaSyCJIPXQboD4ExbjP8SlXi6mlbvjPCslqMQ\"\n",
    "\n",
    "# Create the YouTube API client\n",
    "youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "\n",
    "# Set the user's age and interests\n",
    "age = 25\n",
    "interests = [\"cooking\", \"fitness\", \"travel\"]\n",
    "\n",
    "# Define the search query\n",
    "query = \" \".join(interests)\n",
    "\n",
    "# Use the YouTube API to search for videos matching the query\n",
    "search_response = youtube.search().list(\n",
    "    q=query,\n",
    "    type='video',\n",
    "    part='id,snippet',\n",
    "    maxResults=5,\n",
    "    videoDefinition='high',\n",
    "    videoEmbeddable='true',\n",
    ").execute()\n",
    "\n",
    "# Get the first video from the search results\n",
    "first_video = search_response['items'][0]\n",
    "\n",
    "# Print the video's title and URL\n",
    "print(\"Recommended video:\", first_video['snippet']['title'])\n",
    "print(\"URL:\", \"https://www.youtube.com/watch?v=\" + first_video['id']['videoId'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2a7baf82",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'InstalledAppFlow' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-9ac782487e18>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mcreds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         flow = InstalledAppFlow.from_client_secrets_file(\n\u001b[0m\u001b[0;32m     21\u001b[0m             client_secrets_file, scopes)\n\u001b[0;32m     22\u001b[0m         \u001b[0mcreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_local_server\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mport\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'InstalledAppFlow' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from googleapiclient.discovery import build\n",
    "from google.oauth2.credentials import Credentials\n",
    "\n",
    "# Set up the YouTube Data API client\n",
    "api_service_name = \"youtube\"\n",
    "api_version = \"v3\"\n",
    "client_secrets_file = \"client_secret.json\" # Path to your client secrets file\n",
    "scopes = [\"https://www.googleapis.com/auth/youtube.readonly\"]\n",
    "\n",
    "creds = None\n",
    "if os.path.exists('token.json'):\n",
    "    creds = Credentials.from_authorized_user_file('token.json', scopes)\n",
    "\n",
    "if not creds or not creds.valid:\n",
    "    if creds and creds.expired and creds.refresh_token:\n",
    "        creds.refresh(Request())\n",
    "    else:\n",
    "        flow = InstalledAppFlow.from_client_secrets_file(\n",
    "            client_secrets_file, scopes)\n",
    "        creds = flow.run_local_server(port=0)\n",
    "    with open('token.json', 'w') as token:\n",
    "        token.write(creds.to_json())\n",
    "\n",
    "youtube = build(api_service_name, api_version, credentials=creds)\n",
    "\n",
    "# Set the user ID (replace with your own user ID)\n",
    "user_id = \"me\"\n",
    "\n",
    "# Get the user's viewing history\n",
    "history_response = youtube.activities().list(\n",
    "    part=\"snippet,contentDetails\",\n",
    "    maxResults=50,\n",
    "    fields=\"items(contentDetails(videoId),snippet(title,description))\"\n",
    ").execute()\n",
    "\n",
    "# Extract the video IDs, titles, and descriptions from the response\n",
    "video_ids = [item['contentDetails']['videoId'] for item in history_response['items']]\n",
    "titles = [item['snippet']['title'] for item in history_response['items']]\n",
    "descriptions = [item['snippet']['description'] for item in history_response['items']]\n",
    "\n",
    "# Create a DataFrame from the video details\n",
    "video_df = pd.DataFrame({'id': video_ids, 'title': titles, 'description': descriptions})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d9c159",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load the dataset of videos and their features (e.g. video genre, duration, etc.)\n",
    "video_df = pd.read_csv(\"video_dataset.csv\")\n",
    "\n",
    "# Load the user's viewing history\n",
    "user_history = pd.read_csv(\"user_history.csv\")\n",
    "\n",
    "# Merge the user's history with the video dataset to get the features of the videos the user has watched\n",
    "user_features = pd.merge(user_history, video_df, on='video_id')\n",
    "\n",
    "# Drop duplicate rows (i.e. if the user watched the same video multiple times)\n",
    "user_features = user_features.drop_duplicates(subset=['user_id', 'video_id'])\n",
    "\n",
    "# Pivot the data to create a user-item matrix where each row represents a user and each column represents a video\n",
    "user_item_matrix = user_features.pivot(index='user_id', columns='video_id', values='watched')\n",
    "\n",
    "# Fill missing values with 0 (i.e. if the user hasn't watched the video, assume they haven't watched it)\n",
    "user_item_matrix = user_item_matrix.fillna(0)\n",
    "\n",
    "# Compute cosine similarity between user-item pairs\n",
    "user_similarities = cosine_similarity(user_item_matrix)\n",
    "\n",
    "# Find the top 5 most similar users to the current user\n",
    "user_id = 'user123'\n",
    "user_index = user_item_matrix.index.get_loc(user_id)\n",
    "similar_users = user_similarities[user_index].argsort()[:-6:-1][1:]\n",
    "\n",
    "# Get the videos watched by the most similar users\n",
    "similar_videos = []\n",
    "for i in similar_users:\n",
    "    similar_user_history = user_history[user_history['user_id'] == user_item_matrix.index[i]]\n",
    "    similar_user_features = pd.merge(similar_user_history, video_df, on='video_id')\n",
    "    similar_videos += list(similar_user_features['video_id'].unique())\n",
    "\n",
    "# Remove videos already watched by the current user\n",
    "similar_videos = list(set(similar_videos) - set(user_history['video_id']))\n",
    "\n",
    "# Sort videos by their similarity score to the user's history\n",
    "video_scores = {}\n",
    "for video_id in similar_videos:\n",
    "    video_features = video_df[video_df['video_id'] == video_id].iloc[0]\n",
    "    video_score = cosine_similarity([video_features.iloc[1:].values], [user_item_matrix.loc[user_id, user_item_matrix.columns != 'user_id'].values])[0][0]\n",
    "    video_scores[video_id] = video_score\n",
    "\n",
    "sorted_videos = sorted(video_scores.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "\n",
    "# Print the top 5 recommended videos\n",
    "for video_id, score in sorted_videos:\n",
    "    video_title = video_df[video_df['video_id'] == video_id]['title'].iloc[0]\n",
    "    print(f\"{video_title} (score: {score})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7ffe5c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\marin/.cache\\torch\\hub\\openai_clip_main\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Cannot find callable clip in hubconf",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-da89a1ec8b13>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# Load the CLIP model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreprocess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'openai/clip'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'clip'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\hub.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(repo_or_dir, model, source, trust_repo, force_reload, verbose, skip_validation, *args, **kwargs)\u001b[0m\n\u001b[0;32m    556\u001b[0m                                            verbose=verbose, skip_validation=skip_validation)\n\u001b[0;32m    557\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 558\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_load_local\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepo_or_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    559\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\hub.py\u001b[0m in \u001b[0;36m_load_local\u001b[1;34m(hubconf_dir, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    584\u001b[0m         \u001b[0mhub_module\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_import_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMODULE_HUBCONF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhubconf_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m         \u001b[0mentry\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_load_entry_from_hubconf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhub_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mentry\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\hub.py\u001b[0m in \u001b[0;36m_load_entry_from_hubconf\u001b[1;34m(m, model)\u001b[0m\n\u001b[0;32m    338\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfunc\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 340\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Cannot find callable {} in hubconf'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Cannot find callable clip in hubconf"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the CLIP model\n",
    "model, preprocess = torch.hub.load('openai/clip', 'clip', device=device)\n",
    "model.eval()\n",
    "\n",
    "# Define the image transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    preprocess\n",
    "])\n",
    "\n",
    "# Define the function to generate images from text\n",
    "def generate_image(text, num_images):\n",
    "    # Encode the text prompt\n",
    "    text_encoded = model.encode_text(text.to(device))\n",
    "    \n",
    "    # Generate images from the encoded text prompt\n",
    "    for i in range(num_images):\n",
    "        z = torch.randn([1, 512], device=device)\n",
    "        image_features = model.decode(z, text_encoded)\n",
    "        image = image_features.cpu().detach().numpy().squeeze()\n",
    "        image = np.transpose(image, (1, 2, 0))\n",
    "        image = ((image + 1) / 2.0) * 255.0\n",
    "        image = image.astype(np.uint8)\n",
    "        image = Image.fromarray(image)\n",
    "        image.show()\n",
    "\n",
    "# Define the text prompt\n",
    "text = torch.tensor([preprocess(\"a landscape with mountains and a lake\")]).to(device)\n",
    "\n",
    "# Generate images from the text prompt\n",
    "generate_image(text, num_images=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "54cc00aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "# !pip install git+https://github.com/openai/CLIP.git\n",
    "!pip uninstall torch\n",
    "!pip install torch==1.10.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118af4e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
